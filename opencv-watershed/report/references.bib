@misc{2DPointSets,
  title = {{{2D Point Sets}}},
  urldate = {2025-05-20},
  howpublished = {https://www.redblobgames.com/x/1830-jittered-grid/},
  langid = {american},
  file = {/home/krisspy/snap/zotero-snap/common/Zotero/storage/6ZV8EUQ6/1830-jittered-grid.html}
}

@article{Heapsort2025,
  title = {Heapsort},
  year = {2025},
  month = feb,
  journal = {Wikipedia},
  urldate = {2025-05-20},
  abstract = {In computer science, heapsort is an efficient, comparison-based sorting algorithm that reorganizes an input array into a heap (a data structure where each node is greater than its children) and then repeatedly removes the largest node from that heap, placing it at the end of the array. Although somewhat slower in practice on most machines than a well-implemented quicksort, it has the advantages of very simple implementation and a more favorable worst-case O(n log n) runtime.  Most real-world quicksort variants include an implementation of heapsort as a fallback should they detect that quicksort is becoming degenerate. Heapsort is an in-place algorithm, but it is not a stable sort. Heapsort was invented by J. W. J. Williams in 1964. The paper also introduced the binary heap as a useful data structure in its own right. In the same year, Robert W. Floyd published an improved version that could sort an array in-place, continuing his earlier research into the treesort algorithm.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1274768727},
  file = {/home/krisspy/snap/zotero-snap/common/Zotero/storage/6R6D927H/Heapsort.html}
}

@article{HuffmanCoding2025,
  title = {Huffman Coding},
  year = {2025},
  month = apr,
  journal = {Wikipedia},
  urldate = {2025-05-20},
  abstract = {In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code is Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper "A Method for the Construction of Minimum-Redundancy Codes". The output from Huffman's algorithm can be viewed as a variable-length code table for encoding a source symbol (such as a character in a file).  The algorithm derives this table from the estimated probability or frequency of occurrence (weight) for each possible value of the source symbol.  As in other entropy encoding methods, more common symbols are generally represented using fewer bits than less common symbols.  Huffman's method can be efficiently implemented, finding a code in time linear to the number of input weights if these weights are sorted.  However, although optimal among methods encoding symbols separately, Huffman coding is not always optimal among all compression methods -- it is replaced with arithmetic coding or asymmetric numeral systems if a better compression ratio is required.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1286394000},
  file = {/home/krisspy/snap/zotero-snap/common/Zotero/storage/BPQIVVSR/Huffman_coding.html}
}
